{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE algorithm\n",
    "\n",
    "## Tested on LunarLander-V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of actions: 4\n",
      "State dimension: (8,)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\")\n",
    "# gym compatibility: unwrap TimeLimit\n",
    "if hasattr(env, '_max_episode_steps'):\n",
    "    env = env.env\n",
    "    \n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape\n",
    "print(\"No. of actions:\", n_actions)\n",
    "print(\"State dimension:\", state_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy gradient algorithms\n",
    "Given policy $\\pi(a/s)$, we have expected discounted reward,\n",
    "\n",
    "$$J = \\mathbb{E}_{s-p(s), a-\\pi_\\theta(s/a)}G(s,a) $$\n",
    "\n",
    "If we take J as the objective function and optimize our policy using gradient descent,\n",
    "\n",
    "$$\\theta_{i+1} \\leftarrow \\theta_{i} + \\alpha*\\nabla J$$\n",
    "Where, $\\theta$ is the policy parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDNN(keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(OurDNN, self).__init__()\n",
    "        #Input layer\n",
    "        self.inp = InputLayer(input_dim)\n",
    "        #Hidden layers here - ReLu\n",
    "        self.hd1 = Dense(200,activation='relu')\n",
    "        self.hd2 = Dense(200,activation='relu')\n",
    "        #Output layer here - linear\n",
    "        self.out = Dense(output_dim, kernel_initializer='uniform', activation='linear')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        #Essentially feedforward your network\n",
    "        inp_fwd = self.inp(input_data)\n",
    "        hd1_fwd = self.hd1(inp_fwd)\n",
    "        hd2_fwd = self.hd2(hd1_fwd)\n",
    "        out_fwd = self.out(hd2_fwd)\n",
    "        #Get the output\n",
    "        return out_fwd  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, env, lr=1e-3, gamma=0.99, load=False):\n",
    "        \n",
    "        self.env = env\n",
    "        self.state_dim = env.observation_space.shape\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.optimizer = keras.optimizers.Adam(lr)\n",
    "        \n",
    "        #Create network\n",
    "        if load:\n",
    "            self.network = keras.models.load_model(\"./models/tf2_pg_cartpole\")\n",
    "            self.network.summary()\n",
    "            print(\"Network loaded\")\n",
    "        else:\n",
    "            self.network = OurDNN(self.state_dim, self.n_actions)\n",
    "            self.network.compile(self.optimizer)\n",
    "            print(\"Network created\")\n",
    "            \n",
    "    def get_policies(self, states):\n",
    "        '''\n",
    "        Get the network output, given the states\n",
    "        Since actions are mutually exclusive - using softmax\n",
    "        Here, softmax and log_softmax\n",
    "        '''\n",
    "        logits = self.network(states)\n",
    "        policy = tf.nn.softmax(logits)\n",
    "        log_policy = tf.nn.log_softmax(logits)\n",
    "        return policy, log_policy\n",
    "    \n",
    "    def get_G(self, rewards):\n",
    "        '''\n",
    "        Gets the cumulative reward G(s,a)\n",
    "        '''\n",
    "        rewards.reverse()\n",
    "        cum_rewards = []\n",
    "        cum_rewards.append(rewards[0])\n",
    "        #Go through each reward\n",
    "        for i in range(len(rewards)-1):\n",
    "            cum_rewards.append(rewards[i+1] + self.gamma*cum_rewards[i])\n",
    "        cum_rewards.reverse()\n",
    "        return np.array(cum_rewards).astype('float32')\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Get the sampled action using the current network\n",
    "        '''\n",
    "        policy, _ = self.get_policies(state)\n",
    "        return np.random.choice(self.n_actions, p=policy[0].numpy())\n",
    "    \n",
    "    def get_loss(self, states, actions, G, lamb=0.1):\n",
    "        '''\n",
    "        Get the loss function to optimize for\n",
    "        '''\n",
    "        #Get policy and log_policy first\n",
    "        policy, log_policy = self.get_policies(states)\n",
    "        #Log-policy for actions\n",
    "        indices = tf.stack([tf.range(tf.shape(log_policy)[0]), actions], axis=-1)\n",
    "        log_policy_for_actions = tf.gather_nd(log_policy, indices)\n",
    "        #Objective function\n",
    "        J = tf.reduce_mean(log_policy_for_actions*G)\n",
    "        #Entropy regularization\n",
    "        entropy = -tf.reduce_sum(policy*log_policy, axis=1)\n",
    "        #Get loss\n",
    "        loss = -(J + lamb*entropy)\n",
    "        return loss\n",
    "    \n",
    "    def train_on_session(self, states, actions, rewards):\n",
    "        '''\n",
    "        Given the training samples, update the parameters\n",
    "        '''\n",
    "        G = self.get_G(rewards)\n",
    "        variables = self.network.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.get_loss(states, actions, G)\n",
    "            grads = tape.gradient(loss, variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, variables))\n",
    "        return sum(rewards)\n",
    "    \n",
    "    def save(self):\n",
    "        self.network.save(\"./models/tf2_pg_cartpole\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"our_dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  804       \n",
      "=================================================================\n",
      "Total params: 42,804\n",
      "Trainable params: 42,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Network loaded\n"
     ]
    }
   ],
   "source": [
    "myagent = Agent(env, load=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(agent, t_max=1000):\n",
    "    '''\n",
    "    Play a full session with current agent\n",
    "    '''\n",
    "    states, actions, rewards = [], [], []\n",
    "    s = agent.env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        #Get the action\n",
    "        s = s.astype(np.float32)\n",
    "        a = agent.get_action(s[None])        \n",
    "        new_s, r, done, _ = agent.env.step(a)\n",
    "        #Record\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        \n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return np.array(states), np.array(actions).astype('int32'), rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped\n",
      "mean reward: 163.382 at iter: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tf2_pg_cartpole/assets\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "rewards_log = []\n",
    "max_reward = 0\n",
    "\n",
    "try:\n",
    "    for i in range(100):\n",
    "        rewards = [myagent.train_on_session(*generate_session(myagent)) for _ in range(100)]  # generate new sessions\n",
    "        rewards_log.append(np.mean(rewards))\n",
    "        clear_output(True)\n",
    "        print(\"mean reward: %.3f at iter:\" % (np.mean(rewards)), i+1)\n",
    "        plt.plot(rewards_log)\n",
    "        plt.show()\n",
    "        if rewards_log[i] > max_reward:\n",
    "            max_reward = rewards_log[i]\n",
    "            myagent.save()\n",
    "        if np.mean(rewards) > 200:\n",
    "            print(\"Yamerou!\") \n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    clear_output(True)\n",
    "    print(\"Stopped\")\n",
    "    print(\"mean reward: %.3f at iter:\" % (np.mean(rewards)), i+1)\n",
    "    plt.plot(rewards_log)\n",
    "    plt.show()\n",
    "    myagent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"our_dnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  1800      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  804       \n",
      "=================================================================\n",
      "Total params: 42,804\n",
      "Trainable params: 42,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Network loaded\n"
     ]
    }
   ],
   "source": [
    "#Load the last best agent!\n",
    "myagent = Agent(env, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"LunarLander-v2\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    myagent.env = env_monitor\n",
    "    sessions = [generate_session(myagent) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.2.27445.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
