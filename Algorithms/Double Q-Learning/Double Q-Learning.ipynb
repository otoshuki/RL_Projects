{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Q-Learning\n",
    "## Using TF-2 Keras\n",
    "## Using Experience Replay\n",
    "\n",
    "### Tested on CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the environment\n",
    "env = gym.make(\"CartPole-v0\").env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Checking GPU Use\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDNN(keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(OurDNN, self).__init__()\n",
    "        #Input layer\n",
    "        self.inp = L.InputLayer(input_dim)\n",
    "        #Hidden layers here - ReLu\n",
    "        self.hd1 = L.Dense(200, kernel_initializer='uniform', activation='relu')\n",
    "        self.hd2 = L.Dense(200, kernel_initializer='uniform', activation='relu')\n",
    "        #Output layer here - linear\n",
    "        self.out = L.Dense(output_dim, kernel_initializer='uniform', activation='linear')\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        #Essentially feedforward your network\n",
    "        inp_fwd = self.inp(input_data)\n",
    "        hd1_fwd = self.hd1(inp_fwd)\n",
    "        hd2_fwd = self.hd2(hd1_fwd)\n",
    "        out_fwd = self.out(hd2_fwd)\n",
    "        #Get the output\n",
    "        return out_fwd        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our AQL Agent\n",
    "\n",
    "### The loss function for our agent is defined as - \n",
    "$$ L(w) = { 1 \\over N} \\sum_i (Q(s,a,w) - [r(s,a) + \\gamma \\cdot Q^{old}(s', argmax_{a^*}Q(s', a^*))]) ^2 $$\n",
    "\n",
    "Where\n",
    "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
    "* $\\gamma$ is a discount factor defined two cells above.\n",
    "\n",
    "### The update equation is defined as\n",
    "$$ \\textbf{w} \\leftarrow \\textbf{w} + \\alpha*\\nabla_{\\textbf w}L(\\textbf w)$$\n",
    "\n",
    "### Here we have two identical neural networks!\n",
    "#### 1.Current Q-network which will be used to calculate $Q(s,a)$\n",
    "#### 2. Old snapshot of the network will be used to calculate  $Q^{old}(s',a)$\n",
    "Where $a$ is $argmax_{a^*}Q(s', a^*)$\n",
    "\n",
    "This target network is updated at very target_steps time steps using the params of the Q-network - Hard Copy method\n",
    "\n",
    "Solves the problem of maximization bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurAgent:\n",
    "    def __init__(self, env, alpha=1e-4, epsilon=0.5, gamma=0.99, buffer_size=0, load=False):\n",
    "        \n",
    "        #Set up constants\n",
    "        self.state_dim = env.observation_space.shape\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.env = env\n",
    "        self.optimizer = keras.optimizers.Adam(alpha)\n",
    "        self.buffer = None\n",
    "        \n",
    "        #Create the model - here, the Q-network\n",
    "        if load:\n",
    "            self.model = keras.models.load_model(\"./models/tf2_cart_model/\")\n",
    "            self.model.summary()\n",
    "            \n",
    "        else:\n",
    "            self.model = OurDNN(self.state_dim, self.n_actions)\n",
    "            self.model.compile(self.optimizer)\n",
    "            \n",
    "        #If buffer size is not 0\n",
    "        if buffer_size:\n",
    "            self.buffer = ReplayBuffer(buffer_size)\n",
    "            print(\"LOG: Using Experience Replay\")   \n",
    "        \n",
    "            #If loaded q-network, then directly load\n",
    "        if load:\n",
    "            #Doing this since I had trouble with copying weights\n",
    "            #from a pretrained model\n",
    "            self.old_model = keras.models.load_model(\"./models/tf2_cart_model/\")\n",
    "        #In case it is new\n",
    "        else:\n",
    "            self.old_model = OurDNN(self.state_dim, self.n_actions)\n",
    "            self.old_model.compile(self.optimizer)\n",
    "            self.q_snapshot()\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Uses E-greedy policy to get the agent action\n",
    "        '''\n",
    "        #Approximate the q_values\n",
    "        q_values = self.model.predict(state[None])[0]\n",
    "        #Explore or exploit\n",
    "        ore_or_oit = np.random.choice([0,1], p =[self.epsilon, 1-self.epsilon])\n",
    "        #If wanna explore\n",
    "        if ore_or_oit == 0:\n",
    "            chosen_action = np.random.choice(self.n_actions, 1)[0] #Over uniform dist\n",
    "        #If wanna exploit\n",
    "        else:\n",
    "            chosen_action = np.argmax(q_values)\n",
    "            \n",
    "        return chosen_action\n",
    "\n",
    "    def q_snapshot(self):\n",
    "        '''\n",
    "        Take a snapshot of Q network weights\n",
    "        '''\n",
    "        self.old_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def get_loss(self, state, action, next_state, reward, is_done):\n",
    "        '''\n",
    "        Get the loss function as defined above\n",
    "        '''\n",
    "        #Get ùëÑ(s,a) using our Q network model\n",
    "        pred_q = self.model(np.atleast_2d(state.astype('float32')))\n",
    "        pred_q_for_a = tf.reduce_sum(pred_q * tf.one_hot(action, self.n_actions), axis=1)\n",
    "        \n",
    "        #Get Q(s',a') using our Q network model\n",
    "        pred_next_q = self.model(np.atleast_2d(next_state.astype('float32')))\n",
    "        #Get the optimal action a* from Q(s',a')\n",
    "        opt_act = tf.math.argmax(pred_next_q, axis=1).numpy()[0]\n",
    "        #Get Q_old(s',a') using the snapshot model\n",
    "        pred_q_old = self.old_model(np.atleast_2d(next_state.astype('float32')))\n",
    "        #Get Q_old(s',a*)\n",
    "        pred_q_old = pred_q_old[:,opt_act]\n",
    "        \n",
    "        #Get target Q-value, Q_(s',a')\n",
    "        target_q_for_a = reward + self.gamma*pred_q_old\n",
    "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "        target_q_for_a = tf.where(is_done, reward, target_q_for_a)\n",
    "        \n",
    "        #Calculate loss\n",
    "        #Stop gradient is not required since we only update Q-net\n",
    "        loss = (pred_q_for_a - target_q_for_a) ** 2\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def train_step(self, state, action, next_state, reward, is_done):\n",
    "        '''\n",
    "        Trains the network\n",
    "        '''\n",
    "        #Variables to train - here weight\n",
    "        variables = self.model.trainable_variables\n",
    "        \n",
    "        #Perform semi-grad Q Learning with Adam optimizer\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.get_loss(state, action, next_state, reward, is_done)\n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
    "     \n",
    "    def generate_session(self, t_max=1000, train=False, batch_size=32, snap_steps=100):\n",
    "        '''\n",
    "        Run environment and train\n",
    "        '''\n",
    "        total_reward = 0\n",
    "        s = self.env.reset()\n",
    "        \n",
    "        for t in range(t_max):\n",
    "            a = self.get_action(s)\n",
    "            next_s, r, done, _ = self.env.step(a)\n",
    "            \n",
    "            if train:\n",
    "                self.train_step(s, a, next_s, r, done)\n",
    "                \n",
    "                #If using exp replay to learn\n",
    "                if self.buffer is not None:\n",
    "                    data = (s, a, r, next_s, done)\n",
    "                    self.buffer.add(*data)\n",
    "                    #Sample transitions and update\n",
    "                    s_,a_,r_,next_s_,done_ = self.buffer.sample(batch_size)\n",
    "                    for i in range(batch_size):\n",
    "                        self.train_step(s_[i],\n",
    "                                        a_[i], \n",
    "                                        next_s_[i],\n",
    "                                        r_[i],\n",
    "                                        done_[i])\n",
    "                \n",
    "                #If using target_networks and after target_steps time\n",
    "                if (t%snap_steps==0):\n",
    "                    #Copy weights to target\n",
    "                    self.q_snapshot()\n",
    "            \n",
    "            total_reward += r\n",
    "            s = next_s\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def save(self):\n",
    "        self.model.save(\"./models/tf2_cart_model\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experience replay buffer using deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "#Deque has a better time complexity\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"\n",
    "        Create Replay buffer.\n",
    "        \"\"\"\n",
    "        self._storage = deque(maxlen=size)\n",
    "        self._maxsize = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "    \n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        '''\n",
    "        Add new elements into the FIFO buffer\n",
    "        '''\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        #FIFO check not really required since dequeu checks it\n",
    "        #Now append the data\n",
    "        self._storage.append(data)\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Sample a batch of experiences.\n",
    "        \"\"\"\n",
    "        #Sample random indexes from the buffer\n",
    "        idxes = np.random.randint(len(self._storage), size=batch_size)\n",
    "\n",
    "        #First convert the data to numpy array\n",
    "        np_storage = np.array(self._storage)\n",
    "        \n",
    "        #Now use these indexes to get the samples\n",
    "        samples = np_storage[idxes]\n",
    "        #Return corresponding values\n",
    "        return(\n",
    "#             np.stack(samples[:,0]),\n",
    "            samples[:,0],\n",
    "            samples[:,1],\n",
    "            samples[:,2],\n",
    "#             np.stack(samples[:,3]),\n",
    "            samples[:,3],\n",
    "            samples[:,4]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"our_dnn_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  1000      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  40200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  402       \n",
      "=================================================================\n",
      "Total params: 41,602\n",
      "Trainable params: 41,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "LOG: Using Experience Replay\n"
     ]
    }
   ],
   "source": [
    "#Agent using cartpole environment and Adam optimizer\n",
    "agent = OurAgent(env, buffer_size=1024, load=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #4\tmean reward = 213.000\tepsilon = 0.475\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tf2_cart_model/assets\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "mean_rewards = []\n",
    "max_reward = 0\n",
    "try:\n",
    "    for i in range(1000):\n",
    "        session_rewards = agent.generate_session(train=True)\n",
    "        mean_rewards.append(np.mean(session_rewards))\n",
    "        agent.epsilon *= 0.99\n",
    "        clear_output(True)\n",
    "        print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), agent.epsilon))\n",
    "        plt.plot(mean_rewards)\n",
    "        plt.show()\n",
    "        #Save weights for new best weights\n",
    "        if mean_rewards[i] > max_reward:\n",
    "            max_reward = mean_rewards[i]\n",
    "            agent.save()\n",
    "        if np.mean(session_rewards) > 300:\n",
    "            print(\"You Win! Stop using Keyboard Interrupt\")\n",
    "    #         break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    clear_output(True)\n",
    "    print(\"Stopped\")\n",
    "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), agent.epsilon))\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.show()\n",
    "    #Commenting this saves the last best model\n",
    "#     agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72.0, 82.0, 75.0, 22.0, 133.0, 156.0, 115.0, 33.0, 183.0, 80.0]\n"
     ]
    }
   ],
   "source": [
    "# Record sessions\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    agent.env = env_monitor\n",
    "    sessions = [agent.generate_session(train=False) for _ in range(10)]\n",
    "    print(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.30535.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
