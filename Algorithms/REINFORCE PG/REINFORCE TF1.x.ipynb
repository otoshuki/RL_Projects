{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE algorithm\n",
    "# Policy Gradient based\n",
    "\n",
    "## Using TF1.x\n",
    "## Tested on CartPole-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "# gym compatibility: unwrap TimeLimit\n",
    "if hasattr(env, '_max_episode_steps'):\n",
    "    env = env.env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "state_dim = env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy gradient algorithms\n",
    "Given policy $\\pi(a/s)$, we have expected discounted reward,\n",
    "\n",
    "$$J = \\mathbb{E}_{s-p(s), a-\\pi_\\theta(s/a)}G(s,a) $$\n",
    "\n",
    "If we take J as the objective function and optimize our policy using gradient descent,\n",
    "\n",
    "$$\\theta_{i+1} \\leftarrow \\theta_{i} + \\alpha*\\nabla J$$\n",
    "Where, $\\theta$ is the policy parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input variables, <S,A,R>\n",
    "ph_states = tf.placeholder('float32', (None,) + state_dim, name=\"states\")\n",
    "ph_actions = tf.placeholder('int32', name=\"action_ids\")\n",
    "ph_cumulative_rewards = tf.placeholder('float32', name=\"cumulative_returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.compat.v1.keras.layers import Dense, InputLayer\n",
    "\n",
    "network = keras.Sequential()\n",
    "network.add(InputLayer(state_dim))\n",
    "network.add(Dense(200, activation='relu'))\n",
    "network.add(Dense(200,activation='relu'))\n",
    "network.add(Dense(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 41,602\n",
      "Trainable params: 41,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE algorithm\n",
    "\n",
    "#### Follows Policy gradient but with the following changes\n",
    "##### Given the above objective function, we want its gradient\n",
    "But this is often difficult directly over the policy, so use log-derivative trick to get policy gradient\n",
    "\n",
    "$$\\nabla \\pi(z) = \\pi(z)\\nabla \\log \\pi(z)$$\n",
    "##### This gives the following gradient function with MC sampled approximation\n",
    "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "##### Now, update network parameters theta using this gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our policy is the softmax activation over network output\n",
    "#Since our actions are mutually exclusive-use softmax\n",
    "logits = network(ph_states)\n",
    "policy = tf.nn.softmax(logits)\n",
    "#Log policy for cost gradient calculation\n",
    "log_policy = tf.nn.log_softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(states):\n",
    "    \"\"\" \n",
    "    Predict action probabilities given states.\n",
    "    \"\"\"\n",
    "    return policy.eval({ph_states: [states.astype(np.float32)]})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative rewards\n",
    "$$G_t= r_t + \\gamma * G_{t + 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards,  # rewards at each step\n",
    "                           gamma=0.99  # discount for reward\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    Take a list of immediate rewards r(s,a) for the whole session \n",
    "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
    "    \"\"\"\n",
    "    rewards.reverse()\n",
    "    cum_rewards = []\n",
    "    cum_rewards.append(rewards[0])\n",
    "    #Go through each reward\n",
    "    for i in range(len(rewards)-1):\n",
    "        cum_rewards.append(rewards[i+1] + gamma*cum_rewards[i])\n",
    "    cum_rewards.reverse()\n",
    "    return np.array(cum_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Objective Function using MC\n",
    "\n",
    "The above objective function gradient can be solved using tensorflow's gradient based optimization on this approx objective function below\n",
    "##### Approx objective function\n",
    "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
    "\n",
    "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select log pi(a_i/s_i) for the actions that were actually taken\n",
    "indices = tf.stack([tf.range(tf.shape(log_policy)[0]), ph_actions], axis=-1)\n",
    "log_policy_for_actions = tf.gather_nd(log_policy, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Objective function\n",
    "J = tf.reduce_mean(log_policy_for_actions*ph_cumulative_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'GatherNd_1:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_policy_for_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy regularization\n",
    "Without this, our policy will quickly tend to become deterministic\n",
    "\n",
    "$$ H(p) = -\\sum_{i = 1}^n p_i \\cdot \\log p_i $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = -tf.reduce_sum(policy*log_policy, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 0.1 #entropy regularization parameter\n",
    "loss = -(J + lamb*entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Generation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, t_max=1000):\n",
    "    \"\"\" \n",
    "    Play a full session with REINFORCE agent.\n",
    "    \"\"\"\n",
    "    # arrays to record session\n",
    "    states, actions, rewards = [], [], []\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # action probabilities array aka pi(a|s)       \n",
    "        action_probs = predict_probs(s)\n",
    "        # Sample action with given probabilities.\n",
    "        a = np.random.choice(n_actions, p=action_probs)       \n",
    "        new_s, r, done, info = env.step(a)\n",
    "        # record session history to train later\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_session(states, actions, rewards, t_max=1000):\n",
    "    \"\"\"Given full session, trains agent with policy gradient\"\"\"\n",
    "    cumulative_rewards = get_cumulative_rewards(rewards)\n",
    "    update.run({\n",
    "        ph_states: states,\n",
    "        ph_actions: actions,\n",
    "        ph_cumulative_rewards: cumulative_rewards,\n",
    "    })\n",
    "    return sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer parameters\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward: 353.400 at iter: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "rewards_log = []\n",
    "\n",
    "for i in range(100):\n",
    "    rewards = [train_on_session(*generate_session(env)) for _ in range(100)]  # generate new sessions\n",
    "    rewards_log.append(np.mean(rewards))\n",
    "    clear_output(True)\n",
    "    print(\"mean reward: %.3f at iter:\" % (np.mean(rewards)), i+1)\n",
    "    plt.plot(rewards_log)\n",
    "    plt.show()\n",
    "    if np.mean(rewards) > 300:\n",
    "        print(\"You Win!\") \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This actually works real fast for CartPole-v0, as can be seen by the number of iterations it actually took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    sessions = [generate_session(env_monitor) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.9005.video000064.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
