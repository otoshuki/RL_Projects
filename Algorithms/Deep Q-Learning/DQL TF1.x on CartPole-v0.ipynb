{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate(Deep) Q-Learning\n",
    "## Using TF-1.x\n",
    "### Tested on CartPole-v0\n",
    "\n",
    "##### Tried an oop approach, but I am not sure about TF1 graph flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the environment\n",
    "env = gym.make(\"CartPole-v0\").env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Stuff to do beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#TF stuff\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "import tensorflow.compat.v1.keras.layers as L\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Checking GPU Use\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AQL Agent\n",
    "\n",
    "### The loss function for our agent is defined as - \n",
    "$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')]) ^2 $$\n",
    "\n",
    "Where\n",
    "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
    "* $\\gamma$ is a discount factor defined two cells above.\n",
    "\n",
    "Since $Q_{-}(s',a')$ is kept constant for our semi-grad Q-Learning, we will use `tf.stop_gradient` for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AQLAgent:\n",
    "    def __init__(self, env, epsilon=0.5, gamma=0.99, load=False):\n",
    "        '''\n",
    "        Use load=True to load a previously saved model\n",
    "        '''\n",
    "        #Set up constants\n",
    "        self.state_dim = env.observation_space.shape\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.env = env\n",
    "        #Set up model\n",
    "        if load:\n",
    "            self.model = keras.models.load_model('./models/cart_model.h5')\n",
    "            print(\"Model loaded\")\n",
    "        else:\n",
    "            self.model = self.create_model()\n",
    "            self.model.save('./models/cart_model.h5')\n",
    "            #Print out some details\n",
    "            print(self.model.summary())\n",
    "        \n",
    "        #Placeholders for <s,a,r,s'> and game_end\n",
    "        self.states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + self.state_dim)\n",
    "        self.actions_ph = keras.backend.placeholder(dtype='int32', shape=[None])\n",
    "        self.rewards_ph = keras.backend.placeholder(dtype='float32', shape=[None])\n",
    "        self.next_states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + self.state_dim)\n",
    "        self.is_done_ph = keras.backend.placeholder(dtype='bool', shape=[None])\n",
    "        \n",
    "        #Then performing Q-Learning we have\n",
    "        \n",
    "        #Get ùëÑùúÉ(s,a)\n",
    "        self.pred_q = self.model(self.states_ph)\n",
    "        self.pred_q_for_a = tf.reduce_sum(self.pred_q * tf.one_hot(self.actions_ph, self.n_actions), axis=1)\n",
    "        \n",
    "        #Get Q_(s',a')\n",
    "        self.pred_next_q = self.model(self.next_states_ph)\n",
    "        #Get V_(s',a') using Q\n",
    "        self.next_v = tf.math.reduce_max(self.pred_next_q, axis=1)\n",
    "        #Get target Q-value, Q_(s',a')\n",
    "        self.target_q_for_a = self.rewards_ph + self.gamma*self.next_v\n",
    "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "        self.target_q_for_a = tf.where(self.is_done_ph, self.rewards_ph, self.target_q_for_a)\n",
    "        \n",
    "        #Calculate loss\n",
    "        self.loss = (self.pred_q_for_a - tf.stop_gradient(self.target_q_for_a)) ** 2\n",
    "        self.loss = tf.reduce_mean(self.loss)\n",
    "        \n",
    "        #Training function\n",
    "        self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.loss)   \n",
    "        \n",
    "        if load: \n",
    "            self.model.load_weights('./weights/cart_weights')\n",
    "            print(\"Model weights loaded succesfully\")\n",
    "        \n",
    "    def create_model(self):\n",
    "        '''\n",
    "        Create a simple NN model\n",
    "        '''\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(L.InputLayer(self.state_dim))\n",
    "        model.add(L.Dense(400, kernel_initializer='uniform', activation='relu'))\n",
    "        model.add(L.Dense(400, kernel_initializer='uniform', activation='relu'))\n",
    "        #Output layer\n",
    "        model.add(L.Dense(self.n_actions, kernel_initializer='uniform', activation='linear'))\n",
    "        return model\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Uses E-greedy policy to get the agent action\n",
    "        '''\n",
    "        #Approximate the q_values\n",
    "        q_values = self.model.predict(state[None])[0]\n",
    "        #Explore or exploit\n",
    "        ore_or_oit = np.random.choice([0,1], p =[self.epsilon, 1-self.epsilon])\n",
    "        #If wanna explore\n",
    "        if ore_or_oit == 0:\n",
    "            chosen_action = np.random.choice(self.n_actions, 1)[0] #Over uniform dist\n",
    "        #If wanna exploit\n",
    "        else:\n",
    "            chosen_action = np.argmax(q_values)\n",
    "            \n",
    "        return chosen_action\n",
    "    \n",
    "    def generate_session(self, t_max=1000, train=False):\n",
    "        '''\n",
    "        Run environment and train\n",
    "        '''\n",
    "        total_reward = 0\n",
    "        s = self.env.reset()\n",
    "\n",
    "        for t in range(t_max):\n",
    "            a = self.get_action(s)       \n",
    "            next_s, r, done, _ = self.env.step(a)\n",
    "\n",
    "            if train:\n",
    "                sess.run(self.train_step,{\n",
    "                    self.states_ph: [s], self.actions_ph: [a], self.rewards_ph: [r], \n",
    "                    self.next_states_ph: [next_s], self.is_done_ph: [done]})\n",
    "\n",
    "            total_reward += r\n",
    "            s = next_s\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        return total_reward\n",
    "    \n",
    "    def save(self):\n",
    "        '''\n",
    "        Save the weights\n",
    "        '''\n",
    "        self.model.save_weights('./weights/cart_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "agent = AQLAgent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to train and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6af629785793>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #2\tmean reward = 14.160\tepsilon = 0.485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d5aa717a2a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msession_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d5aa717a2a6a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msession_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-790e3bcda84a>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(self, t_max, train)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 sess.run(self.train_step,{\n\u001b[1;32m     97\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     self.next_states_ph: [next_s], self.is_done_ph: [done]})\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m           \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m           \u001b[0mfeed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "mean_rewards = []\n",
    "\n",
    "for i in range(10000):\n",
    "    session_rewards = [agent.generate_session(train=True) for _ in range(100)]\n",
    "    mean_rewards.append(np.mean(session_rewards))\n",
    "    agent.epsilon *= 0.99\n",
    "    clear_output(True)\n",
    "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), agent.epsilon))\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.show()\n",
    "    #Save weights after every iteration\n",
    "    agent.save()\n",
    "    if np.mean(session_rewards) > 300:\n",
    "        print(\"You Win! Stop using Keyboard Interrupt\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record sessions\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    agent.env = env_monitor\n",
    "    sessions = [agent.generate_session(train=False) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.0.21502.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-202074563d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'state' is not defined"
     ]
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
