{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate(Deep) Q-Learning\n",
    "## Using TF-1.x\n",
    "### Tested on CartPole-v0\n",
    "\n",
    "##### Tried an oop approach, but I am not sure about TF1 graph flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the environment\n",
    "env = gym.make(\"CartPole-v0\").env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Stuff to do beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/otoshuki/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#TF stuff\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "import tensorflow.compat.v1.keras.layers as L\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "#Checking GPU Use\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AQL Agent\n",
    "\n",
    "### The loss function for our agent is defined as - \n",
    "$$ L = { 1 \\over N} \\sum_i (Q_{\\theta}(s,a) - [r(s,a) + \\gamma \\cdot max_{a'} Q_{-}(s', a')]) ^2 $$\n",
    "\n",
    "Where\n",
    "* $s, a, r, s'$ are current state, action, reward and next state respectively\n",
    "* $\\gamma$ is a discount factor defined two cells above.\n",
    "\n",
    "Since $Q_{-}(s',a')$ is kept constant for our semi-grad Q-Learning, we will use `tf.stop_gradient` for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AQLAgent:\n",
    "    def __init__(self, env, epsilon=0.5, gamma=0.99, load=False):\n",
    "        '''\n",
    "        Use load=True to load a previously saved model\n",
    "        '''\n",
    "        #Set up constants\n",
    "        self.state_dim = env.observation_space.shape\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.env = env\n",
    "        #Set up model\n",
    "        if load:\n",
    "            self.model = keras.models.load_model('./models/cart_model.h5')\n",
    "            print(\"Model loaded\")\n",
    "        else:\n",
    "            self.model = self.create_model()\n",
    "            self.model.save('./models/cart_model.h5')\n",
    "            #Print out some details\n",
    "            print(self.model.summary())\n",
    "        \n",
    "        #Placeholders for <s,a,r,s'> and game_end\n",
    "        self.states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + self.state_dim)\n",
    "        self.actions_ph = keras.backend.placeholder(dtype='int32', shape=[None])\n",
    "        self.rewards_ph = keras.backend.placeholder(dtype='float32', shape=[None])\n",
    "        self.next_states_ph = keras.backend.placeholder(dtype='float32', shape=(None,) + self.state_dim)\n",
    "        self.is_done_ph = keras.backend.placeholder(dtype='bool', shape=[None])\n",
    "        \n",
    "        #Then performing Q-Learning we have\n",
    "        \n",
    "        #Get ùëÑùúÉ(s,a)\n",
    "        self.pred_q = self.model(self.states_ph)\n",
    "        self.pred_q_for_a = tf.reduce_sum(self.pred_q * tf.one_hot(self.actions_ph, self.n_actions), axis=1)\n",
    "        \n",
    "        #Get Q_(s',a')\n",
    "        self.pred_next_q = self.model(self.next_states_ph)\n",
    "        #Get V_(s',a') using Q\n",
    "        self.next_v = tf.math.reduce_max(self.pred_next_q, axis=1)\n",
    "        #Get target Q-value, Q_(s',a')\n",
    "        self.target_q_for_a = self.rewards_ph + self.gamma*self.next_v\n",
    "        # at the last state we shall use simplified formula: Q(s,a) = r(s,a) since s' doesn't exist\n",
    "        self.target_q_for_a = tf.where(self.is_done_ph, self.rewards_ph, self.target_q_for_a)\n",
    "        \n",
    "        #Calculate loss\n",
    "        self.loss = (self.pred_q_for_a - tf.stop_gradient(self.target_q_for_a)) ** 2\n",
    "        self.loss = tf.reduce_mean(self.loss)\n",
    "        \n",
    "        #Training function\n",
    "        self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.loss)   \n",
    "        \n",
    "        if load: \n",
    "            self.model.load_weights('./weights/cart_weights')\n",
    "            print(\"Model weights loaded succesfully\")\n",
    "        \n",
    "    def create_model(self):\n",
    "        '''\n",
    "        Create a simple NN model\n",
    "        '''\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(L.InputLayer(self.state_dim))\n",
    "        model.add(L.Dense(400, kernel_initializer='uniform', activation='relu'))\n",
    "        model.add(L.Dense(400, kernel_initializer='uniform', activation='relu'))\n",
    "        #Output layer\n",
    "        model.add(L.Dense(self.n_actions, kernel_initializer='uniform', activation='linear'))\n",
    "        return model\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Uses E-greedy policy to get the agent action\n",
    "        '''\n",
    "        #Approximate the q_values\n",
    "        q_values = self.model.predict(state[None])[0]\n",
    "        #Explore or exploit\n",
    "        ore_or_oit = np.random.choice([0,1], p =[self.epsilon, 1-self.epsilon])\n",
    "        #If wanna explore\n",
    "        if ore_or_oit == 0:\n",
    "            chosen_action = np.random.choice(self.n_actions, 1)[0] #Over uniform dist\n",
    "        #If wanna exploit\n",
    "        else:\n",
    "            chosen_action = np.argmax(q_values)\n",
    "            \n",
    "        return chosen_action\n",
    "    \n",
    "    def generate_session(self, t_max=1000, train=False):\n",
    "        '''\n",
    "        Run environment and train\n",
    "        '''\n",
    "        total_reward = 0\n",
    "        s = self.env.reset()\n",
    "\n",
    "        for t in range(t_max):\n",
    "            a = self.get_action(s)       \n",
    "            next_s, r, done, _ = self.env.step(a)\n",
    "\n",
    "            if train:\n",
    "                sess.run(self.train_step,{\n",
    "                    self.states_ph: [s], self.actions_ph: [a], self.rewards_ph: [r], \n",
    "                    self.next_states_ph: [next_s], self.is_done_ph: [done]})\n",
    "\n",
    "            total_reward += r\n",
    "            s = next_s\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        return total_reward\n",
    "    \n",
    "    def save(self):\n",
    "        '''\n",
    "        Save the weights\n",
    "        '''\n",
    "        self.model.save_weights('./weights/cart_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 400)               2000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 802       \n",
      "=================================================================\n",
      "Total params: 163,202\n",
      "Trainable params: 163,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "agent = AQLAgent(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to train and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #32\tmean reward = 430.340\tepsilon = 0.359\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Win! Stop using Keyboard Interrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4a795593d412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msession_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-4a795593d412>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msession_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmean_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-790e3bcda84a>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(self, t_max, train)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-790e3bcda84a>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     70\u001b[0m         '''\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#Approximate the q_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;31m#Explore or exploit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0more_or_oit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3642\u001b[0m     \u001b[0;31m# this ensures that we return its value as a SparseTensorValue rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3643\u001b[0m     \u001b[0;31m# a SparseTensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_if_composite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2-gpu/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expand_composites\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m     raise ValueError(\n\u001b[1;32m    606\u001b[0m         \u001b[0;34m\"Only valid keyword arguments are `check_types` and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(10000):\n",
    "    session_rewards = [agent.generate_session(train=True) for _ in range(100)]\n",
    "    mean_rewards.append(np.mean(session_rewards))\n",
    "    agent.epsilon *= 0.99\n",
    "    clear_output(True)\n",
    "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\".format(i, np.mean(session_rewards), agent.epsilon))\n",
    "    plt.plot(mean_rewards)\n",
    "    plt.show()\n",
    "    #Save weights after every iteration\n",
    "    agent.save()\n",
    "    if np.mean(session_rewards) > 300:\n",
    "        print(\"You Win! Stop using Keyboard Interrupt\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]\n"
     ]
    }
   ],
   "source": [
    "# Record sessions\n",
    "import gym.wrappers\n",
    "\n",
    "with gym.wrappers.Monitor(gym.make(\"CartPole-v0\"), directory=\"videos\", force=True) as env_monitor:\n",
    "    agent.epsilon = 0 #For tests\n",
    "    agent.env = env_monitor\n",
    "    sessions = [agent.generate_session(train=False) for _ in range(10)]\n",
    "    print(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"videos/openaigym.video.1.7779.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show video. This may not work in some setups. If it doesn't\n",
    "# work for you, you can download the videos and view them locally.\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_names = sorted([s for s in Path('videos').iterdir() if s.suffix == '.mp4'])\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_names[-1]))  # You can also try other indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
