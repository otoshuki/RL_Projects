{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA Algorithm\n",
    "\n",
    "### Tested on CliffWalkingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import gym\n",
    "import gym.envs.toy_text\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value SARSA will be build upon the QLearningAgent class from Q-Learning Algo notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value SARSA Algorithm\n",
    " \n",
    "#### 1. Initlialize Q(s,a) with all zeros\n",
    "#### 2. Using the current Q(s,a) get the best action to take by following - \n",
    "\n",
    "##### 2.a - (THE CHANGE!) V function is the expectation over Q functions for different actions wrt the action probability density\n",
    "$$V(s) = \\mathbb{E}_{a_i ~ \\pi(a_i|s)}Q(s,a_i)$$\n",
    "\n",
    "##### 2.b - Get the new Q function using -\n",
    "$$ \\hat Q(s_t,a_t) = r + \\gamma*V(s)$$\n",
    "\n",
    "##### 2.c - Smooth update of Q function using moving average -\n",
    "$$Q(s_t,a_t)=\\alpha*(\\hat Q(s_t,a_t)) + (1-\\alpha)*Q(s_t,a_t)$$\n",
    "Where, $\\alpha$ is the learning rate\n",
    "\n",
    "##### 2.d - Get the best action using - \n",
    "$$\\pi^*(s) = argmax_a Q(s,a)$$\n",
    "\n",
    "#### 3 - $\\epsilon$ - greedy exploration -\n",
    "Take a random action with probability $\\epsilon$, otherwise use best action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpValSarsaAgent:\n",
    "    \n",
    "    #Step 1\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self, state, action, value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #Step 2.a\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        epsilon = self.epsilon\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        # If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        #First get the probability distribution\n",
    "        state_value = 0\n",
    "        num_actions = len(possible_actions)\n",
    "        for action in possible_actions:\n",
    "            #If the action is the best action\n",
    "            #p(a/s) = (1-E) + E/num_actions\n",
    "            if action == self.get_best_action(state):\n",
    "                p_a_s = (1-epsilon) + epsilon/num_actions\n",
    "            #If not the best action\n",
    "            #p(a/s) = E/num_actions\n",
    "            else:\n",
    "                p_a_s = epsilon/num_actions\n",
    "            state_value += p_a_s * self.get_qvalue(state, action)\n",
    "\n",
    "        return state_value\n",
    "\n",
    "    #Steps 2.b, 2.c\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "        \"\"\"\n",
    "        # agent parameters\n",
    "        gamma = self.discount\n",
    "        learning_rate = self.alpha\n",
    "        \n",
    "        #Get new_q first using V(s')\n",
    "        new_q = reward + gamma*self.get_value(next_state)\n",
    "        #Get moving averaged q_func with new_q and the older q_value\n",
    "        q_func_avg = learning_rate*new_q + (1-learning_rate)*self.get_qvalue(state, action)\n",
    "\n",
    "        self.set_qvalue(state, action, q_func_avg)\n",
    "\n",
    "    #Step 3\n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        #Best action is the argmax over the new functions\n",
    "        q_actions = []\n",
    "        for action in possible_actions:\n",
    "            q_actions.append(self.get_qvalue(state, action))\n",
    "        best_action = possible_actions[np.argmax(q_actions)]\n",
    "            \n",
    "        return best_action\n",
    "\n",
    "    #Step 4\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Taking into account E-Greedy Exploration!\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        # agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        ore_or_oit = np.random.choice([0,1], p =[epsilon, 1-epsilon])\n",
    "        #If wanna explore\n",
    "        if ore_or_oit == 0:\n",
    "            chosen_action = np.random.choice(possible_actions) #Over uniform dist\n",
    "        #If wanna exploit\n",
    "        else:\n",
    "            chosen_action = self.get_best_action(state)\n",
    "            \n",
    "        return chosen_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This is a simple implementation of the Gridworld Cliff\n",
      "    reinforcement learning task.\n",
      "\n",
      "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
      "    by Sutton and Barto:\n",
      "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
      "\n",
      "    With inspiration from:\n",
      "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
      "\n",
      "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
      "        [3, 0] as the start at bottom-left\n",
      "        [3, 11] as the goal at bottom-right\n",
      "        [3, 1..10] as the cliff at bottom-center\n",
      "\n",
      "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
      "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.toy_text.CliffWalkingEnv()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(env.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#x:start, T:exit, C:cliff, o: flat ground\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env, agent, t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function runs a full game till t_max\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s.\n",
    "        a = agent.get_action(s)\n",
    "\n",
    "        next_s, r, done, _ = env.step(a)\n",
    "\n",
    "        agent.update(s, a, r, next_s)\n",
    "\n",
    "        s = next_s\n",
    "        total_reward += r\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ExpValSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
    "                           get_legal_actions=lambda s: range(n_actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVSARSA mean reward = -28.57\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "def moving_average(x, span=100):\n",
    "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i in range(5000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    #Here epsilon is constant\n",
    "    if i % 100 == 0:\n",
    "        clear_output(True)\n",
    "        print('ExpValEVSARSA mean reward =', np.mean(rewards[-100:]))\n",
    "        plt.title(\"epsilon = %s\" % agent.epsilon)\n",
    "        plt.plot(moving_average(rewards), label='ev_sarsa')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_policy(env, agent):\n",
    "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
    "    n_rows, n_cols = env._cliff.shape\n",
    "\n",
    "    actions = '^>v<'\n",
    "\n",
    "    for yi in range(n_rows):\n",
    "        for xi in range(n_cols):\n",
    "            if env._cliff[yi, xi]:\n",
    "                print(\" C \", end='')\n",
    "            elif (yi * n_cols + xi) == env.start_state_index:\n",
    "                print(\" X \", end='')\n",
    "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
    "                print(\" T \", end='')\n",
    "            else:\n",
    "                print(\" %s \" %\n",
    "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpValSARSA\n",
      " >  >  >  >  >  >  >  >  >  >  >  v \n",
      " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
      " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
      " X  C  C  C  C  C  C  C  C  C  C  T \n"
     ]
    }
   ],
   "source": [
    "print(\"ExpValSARSA\")\n",
    "draw_policy(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
