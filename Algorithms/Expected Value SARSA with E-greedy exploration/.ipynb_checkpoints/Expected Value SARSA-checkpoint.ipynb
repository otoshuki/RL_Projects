{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA Algorithm\n",
    "\n",
    "### Tested on CliffWalkingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import gym\n",
    "import gym.envs.toy_text\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value SARSA will be build upon the QLearningAgent class from Q-Learning Algo notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Value SARSA Algorithm\n",
    " \n",
    "#### 1. Initlialize Q(s,a) with all zeros\n",
    "#### 2. Using the current Q(s,a) get the best action to take by following - \n",
    "\n",
    "##### 2.a - (THE CHANGE!) V function is the expectation over Q functions for different actions wrt the action probability density\n",
    "$$V(s) = \\mathbb{E}_{a_i ~ \\pi(a_i|s)}Q(s,a_i)$$\n",
    "\n",
    "##### 2.b - Get the new Q function using -\n",
    "$$ \\hat Q(s_t,a_t) = r + \\gamma*V(s)$$\n",
    "\n",
    "##### 2.c - Smooth update of Q function using moving average -\n",
    "$$Q(s_t,a_t)=\\alpha*(\\hat Q(s_t,a_t)) + (1-\\alpha)*Q(s_t,a_t)$$\n",
    "Where, $\\alpha$ is the learning rate\n",
    "\n",
    "##### 2.d - Get the best action using - \n",
    "$$\\pi^*(s) = argmax_a Q(s,a)$$\n",
    "\n",
    "#### 3 - $\\epsilon$ - greedy exploration -\n",
    "Take a random action with probability $\\epsilon$, otherwise use best action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpValSarsaAgent:\n",
    "    \n",
    "    #Step 1\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self, state, action, value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    #Step 2.a\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        epsilon = self.epsilon\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        # If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        #First get the probability distribution\n",
    "        state_value = 0\n",
    "        num_actions = len(possible_actions)\n",
    "        for action in possible_actions:\n",
    "            #If the action is the best action\n",
    "            #p(a/s) = (1-E) + E/num_actions\n",
    "            if action == self.get_best_action(state):\n",
    "                p_a_s = (1-epsilon) + epsilon/num_actions\n",
    "            #If not the best action\n",
    "            #p(a/s) = E/num_actions\n",
    "            else:\n",
    "                p_a_s = epsilon/num_actions\n",
    "            state_value += p_a_s * self.get_qvalue(state, action)\n",
    "\n",
    "        return state_value\n",
    "\n",
    "    #Steps 2.b, 2.c\n",
    "    def update(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "        \"\"\"\n",
    "        # agent parameters\n",
    "        gamma = self.discount\n",
    "        learning_rate = self.alpha\n",
    "        \n",
    "        #Get new_q first using V(s')\n",
    "        new_q = reward + gamma*self.get_value(next_state)\n",
    "        #Get moving averaged q_func with new_q and the older q_value\n",
    "        q_func_avg = learning_rate*new_q + (1-learning_rate)*self.get_qvalue(state, action)\n",
    "\n",
    "        self.set_qvalue(state, action, q_func_avg)\n",
    "\n",
    "    #Step 3\n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        #Best action is the argmax over the new functions\n",
    "        q_actions = []\n",
    "        for action in possible_actions:\n",
    "            q_actions.append(self.get_qvalue(state, action))\n",
    "        best_action = possible_actions[np.argmax(q_actions)]\n",
    "            \n",
    "        return best_action\n",
    "\n",
    "    #Step 4\n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Taking into account E-Greedy Exploration!\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        # agent parameters:\n",
    "        epsilon = self.epsilon\n",
    "\n",
    "        ore_or_oit = np.random.choice([0,1], p =[epsilon, 1-epsilon])\n",
    "        #If wanna explore\n",
    "        if ore_or_oit == 0:\n",
    "            chosen_action = np.random.choice(possible_actions) #Over uniform dist\n",
    "        #If wanna exploit\n",
    "        else:\n",
    "            chosen_action = self.get_best_action(state)\n",
    "            \n",
    "        return chosen_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    This is a simple implementation of the Gridworld Cliff\n",
      "    reinforcement learning task.\n",
      "\n",
      "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
      "    by Sutton and Barto:\n",
      "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
      "\n",
      "    With inspiration from:\n",
      "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
      "\n",
      "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
      "        [3, 0] as the start at bottom-left\n",
      "        [3, 11] as the goal at bottom-right\n",
      "        [3, 1..10] as the cliff at bottom-center\n",
      "\n",
      "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
      "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.toy_text.CliffWalkingEnv()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(env.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#x:start, T:exit, C:cliff, o: flat ground\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_and_train(env, agent, t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function runs a full game till t_max\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s.\n",
    "        a = agent.get_action(s)\n",
    "\n",
    "        next_s, r, done, _ = env.step(a)\n",
    "\n",
    "        agent.update(s, a, r, next_s)\n",
    "\n",
    "        s = next_s\n",
    "        total_reward += r\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ExpValSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
    "                           get_legal_actions=lambda s: range(n_actions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpValEVSARSA mean reward = -28.95\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "\n",
    "def moving_average(x, span=100):\n",
    "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i in range(5000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    #Here epsilon is constant\n",
    "    if i % 100 == 0:\n",
    "        clear_output(True)\n",
    "        print('ExpValEVSARSA mean reward =', np.mean(rewards[-100:]))\n",
    "        plt.title(\"epsilon = %s\" % agent.epsilon)\n",
    "        plt.plot(moving_average(rewards), label='ev_sarsa')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_policy(env, agent):\n",
    "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
    "    n_rows, n_cols = env._cliff.shape\n",
    "\n",
    "    actions = '^>v<'\n",
    "\n",
    "    for yi in range(n_rows):\n",
    "        for xi in range(n_cols):\n",
    "            if env._cliff[yi, xi]:\n",
    "                print(\" C \", end='')\n",
    "            elif (yi * n_cols + xi) == env.start_state_index:\n",
    "                print(\" X \", end='')\n",
    "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
    "                print(\" T \", end='')\n",
    "            else:\n",
    "                print(\" %s \" %\n",
    "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpValSARSA\n",
      " >  >  >  >  >  >  >  >  >  >  >  v \n",
      " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
      " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
      " X  C  C  C  C  C  C  C  C  C  C  T \n"
     ]
    }
   ],
   "source": [
    "print(\"ExpValSARSA\")\n",
    "draw_policy(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
